{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fábio Capuano de Souza - fullyconvMNIST-NMS.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "1aXVR29SPZqw"
      },
      "cell_type": "markdown",
      "source": [
        "# Redes totalmente convolucionais"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pm_TDUq-PZqy"
      },
      "cell_type": "markdown",
      "source": [
        "Este notebook aborda os seguintes aspectos relacionados às redes totalmente convolucionais:\n",
        "\n",
        "- como transformar uma camada densa em convolucional, aproveitando seus pesos;\n",
        "- como criar, a partir de uma rede pré-treinada para classificar imagens, uma rede totalmente convolucional;\n",
        "- demonstrar que uma rede totalmente convolucional, quando aplicada em imagens maiores que aquelas usadas em seu treinamento, implementa uma varredura implícita com ganhos de eficiência.\n",
        "- apresentar um método de supressão de não máximo para detectar caracteres"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Y_EzemfhPZq3"
      },
      "cell_type": "markdown",
      "source": [
        "## Importando os módulos"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "colab_type": "code",
        "id": "2_Iiv1o4Vuo6",
        "outputId": "dcf23e56-0d2d-449c-c6d7-efc866f45716"
      },
      "cell_type": "code",
      "source": [
        "!pip install matplotlib torch torchvision shapely[vectorized]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x585a0000 @  0x7f477c64f2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.8MB/s \n",
            "\u001b[?25hCollecting shapely[vectorized]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision, shapely\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 shapely-1.6.4.post2 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yCOHxClSWKup"
      },
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/robertoalotufo/ia368z/master/PyTorch/lib/pytorch_trainer_v2.py -Plib/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ro9yOJtrPZq5"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import warnings\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "from shapely import geometry\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# our library\n",
        "from lib import pytorch_trainer_v2 as ptt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "KPnklmAgPZq-",
        "outputId": "d4293aa1-69b1-4196-f252-a27003c1e5c7"
      },
      "cell_type": "code",
      "source": [
        "# verifica se a GPU esta disponivel\n",
        "use_gpu = torch.cuda.is_available()\n",
        "print(\"Usando GPU:\", use_gpu)\n",
        "print('CPU Cores:', os.cpu_count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usando GPU: True\n",
            "CPU Cores: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MPTaqCRtPZrF"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "9nzOiS66xEJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data; mkdir data/MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "QY807Oc2PZrG",
        "outputId": "54100ae6-b9c2-4984-c980-ad1b07247ee1"
      },
      "cell_type": "code",
      "source": [
        "dataset_dir = 'data/MNIST/'\n",
        "\n",
        "# Transformara os dados em tensores no intervalo [0.0, 1.0] (Os dados serão normalizados)\n",
        "data_transform = transforms.ToTensor()\n",
        "# data_transform = None\n",
        "\n",
        "# carrega o conjunto de treinamento e de teste\n",
        "datasets_mnist = dict(train=MNIST(dataset_dir, train=True,  transform=data_transform, download=True),\n",
        "                val  =MNIST(dataset_dir, train=False, transform=data_transform, download=True))\n",
        "\n",
        "print('Amostras para treinamento:', len(datasets_mnist['train']))\n",
        "print('Amostras para validação:', len(datasets_mnist['val']))\n",
        "print(type(datasets_mnist['train'].train_data))\n",
        "print(datasets_mnist['train'].train_data.size())\n",
        "print(datasets_mnist['train'].train_data.min(), datasets_mnist['train'].train_data.max())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "Amostras para treinamento: 60000\n",
            "Amostras para validação: 10000\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([60000, 28, 28])\n",
            "tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8-Vj-yFvxEJR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Definição do dataset com múltiplos dígitos"
      ]
    },
    {
      "metadata": {
        "id": "lK5JKvFJxEJS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testes iniciais"
      ]
    },
    {
      "metadata": {
        "id": "b11V33PYxEJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Função para criar uma imagem de teste, colocando várias amostras\n",
        "def make_sample(dataset, M, seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    N = np.random.randint(5, 8)\n",
        "    char_index = np.random.choice(len(dataset), N, replace=False)\n",
        "\n",
        "    # Empty image and outputs\n",
        "    boxes = []\n",
        "    image = np.zeros((M, M), np.uint8)\n",
        "    object_presence_map = np.zeros((M, M), np.int64)\n",
        "    class_scores_map = -1 * np.ones((M, M), np.int64)\n",
        "    \n",
        "    for k, ix in enumerate(char_index):\n",
        "        img, lab = dataset[ix]\n",
        "        img *= 255\n",
        "        img, lab = img.long(), lab.long()\n",
        "        img, lab = img.numpy(), lab.numpy()\n",
        "        img = img.reshape(28,28)\n",
        "        \n",
        "        # Samples a random position for the digit\n",
        "        x, y = np.random.randint(0, M-29, size=2)\n",
        "        digit_box = geometry.box(x, y, x+28, y+28)\n",
        "        if boxes:\n",
        "            retries = 0\n",
        "            skip = False\n",
        "            # If the digit box intersects with a previous digit, resample\n",
        "            while any(digit_box.intersects(box) for box in boxes):\n",
        "                if retries > 10:\n",
        "                    skip = True\n",
        "                    break\n",
        "                x, y = np.random.randint(0, M-29, size=2)\n",
        "                digit_box = geometry.box(x, y, x+28, y+28)\n",
        "                retries += 1\n",
        "            if skip:\n",
        "                continue\n",
        "        boxes.append(digit_box)\n",
        "                \n",
        "        image[y:y+28, x:x+28] = img\n",
        "        class_scores_map[y:y+28, x:x+28] = lab\n",
        "        # Object presence map equals to 1 inside a shrinked bounding box\n",
        "        object_presence_map[y+10:y+18, x+10:x+18] = 1\n",
        "        \n",
        "    # image = image[np.newaxis, ...]\n",
        "    # object_presence_map = object_presence_map[np.newaxis, ...]\n",
        "    # class_scores_map = class_scores_map[np.newaxis, ...]\n",
        "        \n",
        "    return image, object_presence_map, class_scores_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUz7ImZtxEJV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_sample(sample):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "\n",
        "    img, object_map, class_scores = sample\n",
        "    # Remove batch_size dims\n",
        "    # img = img.squeeze(3)\n",
        "    # object_map = object_map[0]\n",
        "    # class_scores = class_scores[0]\n",
        "    \n",
        "    cax = axs[0].imshow(img, cmap='gray')\n",
        "    axs[0].set_title('Imagem de entrada')\n",
        "    # fig.colorbar(ax=axs[0])\n",
        "\n",
        "    axs[1].imshow(object_map, cmap='gray')\n",
        "    axs[1].set_title('Mapa de presença de objeto')\n",
        "    # fig.colorbar(cax)\n",
        "\n",
        "    cax = axs[2].imshow(class_scores, cmap='rainbow')\n",
        "    axs[2].set_title('Mapa de classes')\n",
        "    fig.colorbar(cax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJhjnREExEJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "24658ecc-9d66-4a24-9d79-1dbdb3121803"
      },
      "cell_type": "code",
      "source": [
        "plot_sample(make_sample(datasets_mnist['train'], M=200, seed=9))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAAEkCAYAAABJxFL3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkkBxptdmmOsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd8cb649e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PpLpuavsxEJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MultiDigitDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, dataset, image_size=(200, 200), transform=None, length=None, random=False):\n",
        "        self.dataset = dataset\n",
        "        self.image_size = image_size\n",
        "        self.length = length or len(dataset)\n",
        "        self.random = random\n",
        "        \n",
        "        self.transform = transform\n",
        "        \n",
        "    def set_length(self, length):\n",
        "        self.length = length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, ix):\n",
        "        seed = ix if not self.random else None\n",
        "        img, obj_map, cls_map = make_sample(self.dataset, self.image_size[0], seed=seed)\n",
        "        \n",
        "        img = img[..., np.newaxis]\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, np.dstack((obj_map, cls_map)).transpose(2, 0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfT_YdTMxEJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizando shapes, dtypes, valores mínimo e máximo"
      ]
    },
    {
      "metadata": {
        "id": "OeDpvlWzxEJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = {\n",
        "    'train': MultiDigitDataset(datasets_mnist['train'], length=128, random=False),\n",
        "    'val': MultiDigitDataset(datasets_mnist['val'], length=128, random=False),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vy6-2IpmxEJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f6f1dafa-4a8d-41fe-ffe5-f70c20a768d9"
      },
      "cell_type": "code",
      "source": [
        "x, y = ds['train'][0]\n",
        "\n",
        "obj_map = y[0]\n",
        "cls_map = y[1]\n",
        "\n",
        "print('x:', x.shape, x.dtype, x.min(), x.max())\n",
        "print('obj_map:', obj_map.shape, obj_map.dtype, obj_map.min(), obj_map.max())\n",
        "print('cls_map:', cls_map.shape, cls_map.dtype, cls_map.min(), cls_map.max())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: (200, 200, 1) uint8 0 255\n",
            "obj_map: (200, 200) int64 0 1\n",
            "cls_map: (200, 200) int64 -1 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RAtEGsg4PZrQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Definição do modelo com camadas densas (igual ao notebook anterior)"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7zlGcXS-PZrR"
      },
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def make_conv_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=out_channels,\n",
        "                      kernel_size=kernel_size,\n",
        "                      padding=padding,\n",
        "                      bias=False,\n",
        "                     ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def make_upsample_block(self, in_channels, out_channels):\n",
        "        layers = [\n",
        "            nn.Upsample(scale_factor=2,\n",
        "                        mode='nearest',\n",
        "                       ),\n",
        "            nn.ConstantPad2d(padding=(1, 0, 1, 0), # Padding Left, Right, Top, Bottom\n",
        "                             value=0,\n",
        "                            ),\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=out_channels,\n",
        "                      kernel_size=2,\n",
        "                      padding=0,\n",
        "                      bias=False,\n",
        "                     ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "        \n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        self.dropout = nn.Dropout2d()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Contracting branch\n",
        "        self.conv1_1 = self.make_conv_block(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.conv1_2 = self.make_conv_block(in_channels=16, out_channels=8, kernel_size=1, padding=0)\n",
        "        self.conv1_3 = self.make_conv_block(in_channels=8, out_channels=16, kernel_size=3)\n",
        "        self.conv1_4 = self.make_conv_block(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.conv1_5 = self.make_conv_block(in_channels=32, out_channels=16, kernel_size=1, padding=0)\n",
        "        self.conv1_6 = self.make_conv_block(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.middle_conv_1 = self.make_conv_block(in_channels=32, out_channels=64)\n",
        "        self.middle_conv_2 = self.make_conv_block(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
        "        self.middle_conv_3 = self.make_conv_block(in_channels=32, out_channels=64)\n",
        "        \n",
        "        \n",
        "        # Expanding branch\n",
        "        self.upconv_1 = self.make_upsample_block(in_channels=64, out_channels=32)\n",
        "        self.conv2_1 = self.make_conv_block(in_channels=64, out_channels=32, kernel_size=3)\n",
        "        self.conv2_2 = self.make_conv_block(in_channels=32, out_channels=16, kernel_size=1, padding=0)\n",
        "        self.conv2_3 = self.make_conv_block(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.upconv_2 = self.make_upsample_block(in_channels=32, out_channels=16)\n",
        "        self.conv2_4 = self.make_conv_block(in_channels=32, out_channels=16, kernel_size=3)\n",
        "        self.conv2_5 = self.make_conv_block(in_channels=16, out_channels=8, kernel_size=1, padding=0)\n",
        "        self.conv2_6 = self.make_conv_block(in_channels=8, out_channels=16, kernel_size=3)\n",
        "         \n",
        "        # Final layer\n",
        "        # out_channels=12: \n",
        "        #    2 channels for object and non-object probability scores)\n",
        "        #    10 channels for prob scores of the 10 classes\n",
        "        self.final_conv = nn.Conv2d(in_channels=16, out_channels=12, kernel_size=1, padding=0, bias=True)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # print('initial:', x.shape)\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x_H_1 = self.conv1_3(x)    # H, W\n",
        "        # print('antes MP1:', x_H_1.shape)\n",
        "        x = self.max_pool(x_H_1)   # H/2, W/2\n",
        "        # print(x.shape)\n",
        "        x = self.conv1_4(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv1_5(x)\n",
        "        # print(x.shape)\n",
        "        x_H2_1 = self.conv1_6(x)   # H/2, W/2\n",
        "        # print('antes MP2:', x_H2_1.shape)\n",
        "        x = self.max_pool(x_H2_1)  # H/4, W/4\n",
        "        # x = self.dropout(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        x = self.middle_conv_1(x)    # H/4, W/4\n",
        "        x = self.middle_conv_2(x)\n",
        "        x = self.middle_conv_3(x)\n",
        "        # print('middle:', x.shape)\n",
        "\n",
        "        x_H2_2 = self.upconv_1(x)   # H/2, W/2\n",
        "        # print('upconv1:', x_H2_2.shape)\n",
        "        \n",
        "        x_H2 = torch.cat((x_H2_1, x_H2_2), dim=1)\n",
        "        # print('cat:', x_H2.shape)\n",
        "        # x_H2 = self.dropout(x_H2)\n",
        "        \n",
        "        x = self.conv2_1(x_H2)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.conv2_3(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        x_H_2 = self.upconv_2(x)    # H, W\n",
        "        # print('upconv2:', x_H_2.shape)\n",
        "        \n",
        "        x_H = torch.cat((x_H_1, x_H_2), dim=1)\n",
        "        # print('cat:', x_H.shape)\n",
        "        # x_H = self.dropout(x_H)\n",
        "        \n",
        "        x = self.conv2_4(x_H)\n",
        "        x = self.conv2_5(x)\n",
        "        x = self.conv2_6(x)\n",
        "        # print('antes final:', x.shape)\n",
        "        \n",
        "        y = self.final_conv(x)\n",
        "        \n",
        "        # # Object and non-object scores\n",
        "        # obj_scores = x[:, :2, :, :]\n",
        "        # # Class scores\n",
        "        # class_scores = x[:, 2:, :, :]\n",
        "        \n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYKtKqmhxEJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGmORCinxEJr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testando o shape de saída"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "xOyUEuQuxEJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24b6bb37-0e8a-4587-d34e-9b059d579b66"
      },
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "x = torch.randn((1, 1, 200, 200))\n",
        "y = model(x)\n",
        "print(y.shape)\n",
        "print('Input and output have same spatial dimensions?', x.shape[2:] == y.shape[2:])\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12, 200, 200])\n",
            "Input and output have same spatial dimensions? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ez6UmarCxEJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinamento com Overfit"
      ]
    },
    {
      "metadata": {
        "id": "jp1BHx9fxEJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Datasets e DataLoaders"
      ]
    },
    {
      "metadata": {
        "id": "EFqiCLLwxEJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = {\n",
        "    'train': MultiDigitDataset(datasets_mnist['train'],\n",
        "                               length=16,\n",
        "                               transform=torchvision.transforms.ToTensor(),\n",
        "                               random=False),\n",
        "    'val': MultiDigitDataset(datasets_mnist['val'],\n",
        "                             length=16,\n",
        "                             transform=torchvision.transforms.ToTensor(),\n",
        "                             random=False),\n",
        "}\n",
        "\n",
        "dls = {\n",
        "    'train': data.DataLoader(ds['train'], batch_size=16, num_workers=os.cpu_count(), shuffle=False),\n",
        "    'val': data.DataLoader(ds['val'], batch_size=16, num_workers=os.cpu_count(), shuffle=False),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WQ43PCkxEJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1feac73a-193d-41d9-cdca-253ae19cf870"
      },
      "cell_type": "code",
      "source": [
        "X, Y = next(iter(dls['train']))\n",
        "\n",
        "print(X.shape, X.type(), X.min(), X.max())\n",
        " \n",
        "print(Y.shape, Y.type(), Y.min(), Y.max())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 200, 200]) torch.FloatTensor tensor(0.) tensor(1.)\n",
            "torch.Size([16, 2, 200, 200]) torch.LongTensor tensor(-1) tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQppS9TCxEJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "192048d0-c3ed-44bb-9690-21b8ba93dd14"
      },
      "cell_type": "code",
      "source": [
        "X, Y = next(iter(dls['val']))\n",
        "\n",
        "print(X.shape, X.type(), X.min(), X.max())\n",
        "\n",
        "print(Y.shape, Y.type(), Y.min(), Y.max())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 200, 200]) torch.FloatTensor tensor(0.) tensor(1.)\n",
            "torch.Size([16, 2, 200, 200]) torch.LongTensor tensor(-1) tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T_6nZgKMxEJ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Trainer"
      ]
    },
    {
      "metadata": {
        "id": "abYXc9azxEJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CombinedLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, obj_presence_weights=[0.05, 5]):\n",
        "        super().__init__()\n",
        "        obj_presence_weights = torch.tensor(obj_presence_weights)\n",
        "        self.CE_obj = nn.CrossEntropyLoss(weight=obj_presence_weights)\n",
        "        self.CE_cls = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "        \n",
        "    def __call__(self, Ypred, Y):\n",
        "        obj_map = Y[:, 0, :, :]\n",
        "        cls_map = Y[:, 1, :, :]\n",
        "        \n",
        "        obj_map_pred = Ypred[:, :2, :, :]\n",
        "        cls_map_pred = Ypred[:, 2:, :, :]\n",
        "        \n",
        "        obj_loss = self.CE_obj(obj_map_pred, obj_map)\n",
        "        cls_loss = self.CE_cls(cls_map_pred, cls_map)\n",
        "        \n",
        "        return obj_loss + cls_loss\n",
        "\n",
        "\n",
        "class MyTrainer(ptt.DeepNetTrainer):\n",
        "    \n",
        "    def __init__(self, model, lr, devname='cpu', **kwargs):\n",
        "        self.dev_name = devname\n",
        "        device = torch.device(self.dev_name)\n",
        "        \n",
        "        self.model = model.to(device)\n",
        "        \n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "        criterion = CombinedLoss().to(device)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.3)\n",
        "        \n",
        "        super().__init__(model,\n",
        "                         optimizer=optimizer,\n",
        "                         criterion=criterion,\n",
        "                         lr_scheduler=scheduler,\n",
        "                         devname=devname,\n",
        "                         **kwargs)\n",
        "    \n",
        "    \n",
        "    def _do_optimize(self, X, Y):\n",
        "        self.optimizer.zero_grad()\n",
        "        Ypred = self.model.forward(X)\n",
        "        loss = self.criterion(Ypred, Y)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return Ypred, loss\n",
        "\n",
        "    def _do_evaluate(self, X, Y):\n",
        "        Ypred = self.model.forward(X)\n",
        "        loss = self.criterion(Ypred, Y)\n",
        "        return Ypred, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTaUuTamxEJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMcXfuchxEJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cb_chkpt = ptt.ModelCheckpoint('.models/multi_MNIST_v2_overfit', reset=True, verbose=1, load_best=True)\n",
        "\n",
        "trainer = MyTrainer(model,\n",
        "                    lr=0.3,\n",
        "                    devname=0,\n",
        "                    callbacks = [ptt.PrintCallback(),\n",
        "                                 cb_chkpt],\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "naVNh9YrxEJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "trainer.fit_loader(n_epochs, dls['train'], dls['val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ixE6g2Z2xEJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinando com dataset maior"
      ]
    },
    {
      "metadata": {
        "id": "pIDyyRYoxEKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds = {\n",
        "    'train': MultiDigitDataset(datasets_mnist['train'],\n",
        "                               length=12800,\n",
        "                               transform=torchvision.transforms.ToTensor(),\n",
        "                               random=True),\n",
        "    'val': MultiDigitDataset(datasets_mnist['val'],\n",
        "                             length=1280,\n",
        "                             transform=torchvision.transforms.ToTensor(),\n",
        "                             random=False),\n",
        "}\n",
        "\n",
        "dls = {\n",
        "    'train': data.DataLoader(ds['train'], batch_size=64, num_workers=os.cpu_count(), shuffle=False),\n",
        "    'val': data.DataLoader(ds['val'], batch_size=64, num_workers=os.cpu_count(), shuffle=False),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0XppH_spxEKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kRAAFaWNxEKF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cb_chkpt = ptt.ModelCheckpoint('.models/multi_MNIST_v2', reset=False, verbose=1, load_best=True)\n",
        "\n",
        "trainer = MyTrainer(model,\n",
        "                    lr=0.03,\n",
        "                    devname=0,\n",
        "                    callbacks = [ptt.PrintCallback(),\n",
        "                                 cb_chkpt],\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ev4keKzzxEKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "trainer.fit_loader(n_epochs, dls['train'], dls['val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4JELXRlxEKL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load do modelo\n",
        "trainer.fit_loader(0, dls['train'], dls['val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4q1ju-nSxEKP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Avaliação\n"
      ]
    },
    {
      "metadata": {
        "id": "p5rU2vXxxEKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = model.eval()\n",
        "\n",
        "ds['eval'] =  MultiDigitDataset(datasets_mnist['val'],\n",
        "                               length=12800,\n",
        "                               transform=torchvision.transforms.ToTensor(),\n",
        "                               random=True,\n",
        "                               image_size=(200, 200))\n",
        "\n",
        "dls = {\n",
        "    'eval': data.DataLoader(ds['eval'], batch_size=64, num_workers=1, shuffle=False),\n",
        "}\n",
        "\n",
        "X, Y = next(iter(dls['eval']))\n",
        "\n",
        "sample_no = 63\n",
        "x = X[sample_no:sample_no+1, ...]\n",
        "y = Y[sample_no, ...]\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(x.to(0))\n",
        "y_pred = y_pred.cpu()\n",
        "\n",
        "x = (x[0][0] * 255).byte()\n",
        "print(x.shape, x.min(), x.max(), x.type())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vi5q4_qJxEKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "obj_map_pred = y_pred[0][:2]\n",
        "print(obj_map_pred.shape)\n",
        "\n",
        "cls_map_pred = y_pred[0][2:]\n",
        "print(cls_map_pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxe8UjmRxEKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "obj_map_pred[1].min(), obj_map_pred[1].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MLwHni5YxEKX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_sample((x, y[0].numpy(), y[1].numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hoY-Qwz8xEKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Probabilidade de presença de objeto\n",
        "obj_map_prob = F.softmax(obj_map_pred, dim=0)[1,:,:]\n",
        "print(obj_map_prob.shape)\n",
        "# Probabilidade das classes\n",
        "cls_map_prob = F.softmax(cls_map_pred, dim=0)\n",
        "\n",
        "max_cls_prob, cls_pred = torch.max(cls_map_prob, dim=0)\n",
        "print(max_cls_prob.shape)\n",
        "print(cls_pred.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVSWmWnHxEKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mapa de presença de objeto\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(obj_map_prob.numpy(), cmap='gray')\n",
        "axs[0].set_title('Probabilidade P(obj)')\n",
        "\n",
        "cax = axs[1].imshow(max_cls_prob.numpy(), cmap='gray')\n",
        "axs[1].set_title('max(P(classe))')\n",
        "\n",
        "cax = axs[2].imshow(max_cls_prob.numpy() * obj_map_prob, cmap='gray')\n",
        "axs[2].set_title('max(P(classe)) * P(obj)')\n",
        "fig.colorbar(cax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKsvaCtOxEKf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "obj_presence = obj_map_prob.numpy() > 0.5\n",
        "cls_map = np.where(obj_presence, cls_pred, -1)\n",
        "\n",
        "plot_sample((x, obj_presence, cls_map))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mx1OpYPgxEKh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold = 0.75\n",
        "final_pred = np.where(obj_map_prob > threshold, cls_pred, -1)\n",
        "\n",
        "plt.imshow(final_pred, cmap='rainbow')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNDXVci7xEKj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tentando implementar non-maximum suppression"
      ]
    },
    {
      "metadata": {
        "id": "iFo0KzzLxEKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_boxes(all_cls_probs, p_thresh=0.75):\n",
        "    boxes = []\n",
        "    for C in range(10):\n",
        "        cls_probs = all_cls_probs[C]\n",
        "        cls_boxes = []\n",
        "        H, W = cls_probs.shape\n",
        "        \n",
        "        i, j = np.unravel_index(np.argsort(cls_probs, axis=None), (H, W))\n",
        "        \n",
        "        # Threshold the probs\n",
        "        sorted_probs = cls_probs[(i, j)]\n",
        "        th_probs = np.argwhere(sorted_probs > p_thresh)\n",
        "        if len(th_probs):\n",
        "            N = th_probs.shape[1]\n",
        "            i, j = i[-N:], j[-N:]\n",
        "\n",
        "            # Bboxes de 28x28\n",
        "            x1 = np.maximum(j-13, 0)\n",
        "            y1 = np.maximum(i-13, 0)\n",
        "            x2 = np.minimum(j+14, W)\n",
        "            y2 = np.minimum(i+14, H)\n",
        "            p = sorted_probs[-N:]\n",
        "            cls_boxes = np.stack((x1, y1, x2, y2, p), axis=1)\n",
        "                    \n",
        "        boxes.append(cls_boxes)\n",
        "\n",
        "    return boxes\n",
        "        \n",
        "        \n",
        "# Malisiewicz et al.\n",
        "# fonte: https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "    # if there are no boxes, return an empty list\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # if the bounding boxes integers, convert them to floats --\n",
        "    # this is important since we'll be doing a bunch of divisions\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # initialize the list of picked indexes\t\n",
        "    pick = []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:,0]\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,2]\n",
        "    y2 = boxes[:,3]\n",
        "\n",
        "    # compute the area of the bounding boxes and sort the bounding\n",
        "    # boxes by the bottom-right y-coordinate of the bounding box\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes\n",
        "    # list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the\n",
        "        # index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # find the largest (x, y) coordinates for the start of\n",
        "        # the bounding box and the smallest (x, y) coordinates\n",
        "        # for the end of the bounding box\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # compute the width and height of the bounding box\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # compute the ratio of overlap\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        # delete all indexes from the index list that have\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    # return only the bounding boxes that were picked using the\n",
        "    # integer data type\n",
        "    return boxes[pick].astype(\"int\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YO6x0dmgxEKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizando"
      ]
    },
    {
      "metadata": {
        "id": "DIcx4y6jxEKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_cls_probs = cls_map_prob * obj_map_prob\n",
        "\n",
        "all_boxes = get_boxes(final_cls_probs, p_thresh=0.9)\n",
        "\n",
        "iou_thresh = 0.3\n",
        "nms_boxes = [non_max_suppression_fast(boxes, iou_thresh) for boxes in all_boxes]\n",
        "\n",
        "mean_nms_boxes = [mean_non_max_suppression_fast(boxes, iou_thresh) for boxes in all_boxes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "DpNOxPk_xEKt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = x.numpy().copy()\n",
        "img = np.dstack((img, img, img))\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axs[0].imshow(img)\n",
        "axs[1].imshow(img)\n",
        "\n",
        "color_list = plt.cm.gist_rainbow(np.linspace(0, 1, 10))\n",
        "\n",
        "# Todas as bounding boxes\n",
        "for C in range(10):\n",
        "    color = color_list[C]\n",
        "    cls_boxes = all_boxes[C]\n",
        "    for box in cls_boxes:\n",
        "        h = box[3] - box[1]\n",
        "        w = box[2] - box[0]\n",
        "        patch = axs[0].add_patch(patches.Rectangle(box[:2], w, h, fill=False, edgecolor=color, lw=2))\n",
        "\n",
        "\n",
        "# Bboxes após NMS\n",
        "\n",
        "for C in range(10):\n",
        "    color = color_list[C]\n",
        "    cls_boxes = nms_boxes[C]\n",
        "    for box in cls_boxes:\n",
        "        h = box[3] - box[1]\n",
        "        w = box[2] - box[0]\n",
        "        patch = axs[1].add_patch(patches.Rectangle(box[:2], w, h, fill=False, edgecolor=color, lw=2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MR84M_vUPZtI"
      },
      "cell_type": "markdown",
      "source": [
        "## Tentando implementar NMS com média das BBoxes"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BHeCAtuDPZtJ"
      },
      "cell_type": "code",
      "source": [
        "def mean_non_max_suppression_fast(boxes, overlapThresh):\n",
        "    # if there are no boxes, return an empty list\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # if the bounding boxes integers, convert them to floats --\n",
        "    # this is important since we'll be doing a bunch of divisions\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # mean boxes\n",
        "    mean_boxes = []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:,0]\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,2]\n",
        "    y2 = boxes[:,3]\n",
        "    p = boxes[:, 4]\n",
        "\n",
        "    # compute the area of the bounding boxes and sort the bounding\n",
        "    # boxes by the bottom-right y-coordinate of the bounding box\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes\n",
        "    # list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the\n",
        "        # index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "\n",
        "        # find the largest (x, y) coordinates for the start of\n",
        "        # the bounding box and the smallest (x, y) coordinates\n",
        "        # for the end of the bounding box\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # compute the width and height of the bounding box\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # compute the ratio of overlap\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "        \n",
        "        # Calculate the mean box for all overlapping boxes\n",
        "        box_ixs = np.where(overlap > overlapThresh)[0]\n",
        "        p_sum = p[last] + p[box_ixs].sum()\n",
        "        mean_box = p[last] * boxes[last, :4] + np.sum(p[box_ixs][:, np.newaxis] * boxes[box_ixs, :4], axis=0)\n",
        "        mean_box = mean_box / p_sum\n",
        "        mean_boxes.append(mean_box)\n",
        "        \n",
        "        # delete all indexes from the index list that have\n",
        "        # been used\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], box_ixs)))\n",
        "\n",
        "    return np.round(np.stack(mean_boxes, axis=0)).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpVUGTxyxEKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizando as bounding boxes para comparar"
      ]
    },
    {
      "metadata": {
        "id": "vkqV6XvfxEKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_cls_probs = cls_map_prob * obj_map_prob\n",
        "\n",
        "all_boxes = get_boxes(final_cls_probs, p_thresh=0.9)\n",
        "\n",
        "iou_thresh = 0.5\n",
        "nms_boxes = [non_max_suppression_fast(boxes, iou_thresh) for boxes in all_boxes]\n",
        "\n",
        "mean_nms_boxes = [mean_non_max_suppression_fast(boxes, iou_thresh) for boxes in all_boxes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7NWC4t3xEK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = x.numpy().copy()\n",
        "img = np.dstack((img, img, img))\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axs[0].imshow(img)\n",
        "axs[1].imshow(img)\n",
        "\n",
        "color_list = plt.cm.gist_rainbow(np.linspace(0, 1, 10))\n",
        "\n",
        "# Todas as bounding boxes\n",
        "for C in range(10):\n",
        "    color = color_list[C]\n",
        "    cls_boxes = all_boxes[C]\n",
        "    for box in cls_boxes:\n",
        "        h = box[3] - box[1]\n",
        "        w = box[2] - box[0]\n",
        "        patch = axs[0].add_patch(patches.Rectangle(box[:2], w, h, fill=False, edgecolor=color, lw=2))\n",
        "        axs[0].set_title('All bboxes')\n",
        "\n",
        "\n",
        "# Bboxes após NMS\n",
        "\n",
        "for C in range(10):\n",
        "    color = color_list[C]\n",
        "    cls_boxes = nms_boxes[C]\n",
        "    for box in cls_boxes:\n",
        "        h = box[3] - box[1]\n",
        "        w = box[2] - box[0]\n",
        "        patch = axs[1].add_patch(patches.Rectangle(box[:2], w, h, fill=False, edgecolor=color, lw=2))\n",
        "        axs[1].set_title('Bboxes after NMS (colored) and Mean NMS (white)')\n",
        "\n",
        "        \n",
        "\n",
        "# Bboxes após Mean NMS\n",
        "for C in range(10):\n",
        "    color = color_list[C]\n",
        "    cls_boxes = mean_nms_boxes[C]\n",
        "    for box in cls_boxes:\n",
        "        h = box[3] - box[1]\n",
        "        w = box[2] - box[0]\n",
        "        patch = axs[1].add_patch(patches.Rectangle(box[:2], w, h, fill=False, edgecolor='white', lw=2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUtsHWIgxEK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}